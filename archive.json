{
  "magic": "E!vIA5L86J2I",
  "timestamp": "2025-09-11T00:04:56.983528+00:00",
  "repo": "SamuelSchlesinger/draft-act",
  "labels": [
    {
      "name": "bug",
      "description": "Something isn't working",
      "color": "d73a4a"
    },
    {
      "name": "documentation",
      "description": "Improvements or additions to documentation",
      "color": "0075ca"
    },
    {
      "name": "duplicate",
      "description": "This issue or pull request already exists",
      "color": "cfd3d7"
    },
    {
      "name": "enhancement",
      "description": "New feature or request",
      "color": "a2eeef"
    },
    {
      "name": "good first issue",
      "description": "Good for newcomers",
      "color": "7057ff"
    },
    {
      "name": "help wanted",
      "description": "Extra attention is needed",
      "color": "008672"
    },
    {
      "name": "invalid",
      "description": "This doesn't seem right",
      "color": "e4e669"
    },
    {
      "name": "question",
      "description": "Further information is requested",
      "color": "d876e3"
    },
    {
      "name": "wontfix",
      "description": "This will not be worked on",
      "color": "ffffff"
    }
  ],
  "issues": [
    {
      "number": 1,
      "id": "I_kwDOPc24Mc7FnraH",
      "title": "Use CFRG boiler plate for prime order groups",
      "url": "https://github.com/SamuelSchlesinger/draft-act/issues/1",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Ristretto255 will work great for many, but some will likely need NIST curves like P-256 or P-384. The simplest thing would be to use a generic prime order group. Many CFRG drafts use the same boiler plate API for this, [as does ARC](https://chris-wood.github.io/draft-arc/draft-yun-cfrg-arc.html#name-prime-order-group). I suggest adopting this API here as well. Not only will this make it easier to adopt new curves, it also aligns the draft closer to what IETF WGs are used to.",
      "createdAt": "2025-08-12T19:08:47Z",
      "updatedAt": "2025-08-12T19:09:35Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 2,
      "id": "I_kwDOPc24Mc7Fn6Gj",
      "title": "Replace BLAKE3 with SHAKE128 or TurboSHAKE128",
      "url": "https://github.com/SamuelSchlesinger/draft-act/issues/2",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "BLAKE3 is not \"standard\" in the sense that no standards organizations has endorsed a specification of it (at least not to my knowledge). This may be a deal breaker for some deployment scenarios.\n\nBoth SHAKE128 as specified in [FIPS 202](https://csrc.nist.gov/pubs/fips/202/final) and TurboSHAKE128 as specified in [draft-irtf-cfrg-kangaroo-twelve](https://datatracker.ietf.org/doc/draft-irtf-cfrg-kangarootwelve/) are viable options. As of writing, [draft-irtf-cfrg-fiat-shamir](https://www.ietf.org/archive/id/draft-irtf-cfrg-fiat-shamir-00) uses SHAKE128.\n\nAn alternative would be to try and get [BLAKE3 at CFRG](https://mailarchive.ietf.org/arch/msg/cfrg/ZSbnJbI1JUkf_VHO4A97TYFFmTQ/). However, my preference would be to not make this a blocker unless there is a compelling reason, e.g., we need the performance benefit.",
      "createdAt": "2025-08-12T19:23:23Z",
      "updatedAt": "2025-08-13T14:31:19Z",
      "closedAt": null,
      "comments": [
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "We should benchmark this change in the prototype before attempting to get BLAKE3 at CFRG. Either way, making the scheme modular with a hash function as an input seems reasonable as well.",
          "createdAt": "2025-08-13T09:05:56Z",
          "updatedAt": "2025-08-13T09:05:56Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "NONE",
          "body": "Ah, that's a good idea in any case!",
          "createdAt": "2025-08-13T14:31:19Z",
          "updatedAt": "2025-08-13T14:31:19Z"
        }
      ]
    },
    {
      "number": 3,
      "id": "I_kwDOPc24Mc7Fn8Mu",
      "title": "Adopt RFC 9380 for hashing to Ristretto255",
      "url": "https://github.com/SamuelSchlesinger/draft-act/issues/3",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "As specified in [Appendix B](https://www.rfc-editor.org/rfc/rfc9380.html#appendix-B). The same RFC specifies algorithms for NIST curves as well (#1).",
      "createdAt": "2025-08-12T19:25:48Z",
      "updatedAt": "2025-08-12T19:25:48Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 4,
      "id": "I_kwDOPc24Mc7Fn_g-",
      "title": "Align terminology with draft-yun-cfrg-arc as much as possible",
      "url": "https://github.com/SamuelSchlesinger/draft-act/issues/4",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "[ARC](datatracker.ietf.org/doc/draft-yun-cfrg-arc/) and ACT are useful for similar, though not identical use cases. I would expect that many who want to adopt ACT would also want to adopt ARC. In order to improve communication, it would be useful to align terminology between the two drafts wherever possible.",
      "createdAt": "2025-08-12T19:29:19Z",
      "updatedAt": "2025-08-13T09:04:12Z",
      "closedAt": null,
      "comments": [
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "Sounds great insofar as they have shared concepts or primitives. For instance, once we implement the range proof in ARC, we should align on that.",
          "createdAt": "2025-08-13T09:04:04Z",
          "updatedAt": "2025-08-13T09:04:12Z"
        }
      ]
    },
    {
      "number": 5,
      "id": "I_kwDOPc24Mc7FoELi",
      "title": "Adopt draft-irtf-cfrg-fiat-shamir and draft-irtf-cfrg-sigma-protocols",
      "url": "https://github.com/SamuelSchlesinger/draft-act/issues/5",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "armfazh"
      ],
      "labels": [],
      "body": "CFRG recently signed up to work out [Sigma protocols](https://datatracker.ietf.org/doc/draft-irtf-cfrg-sigma-protocols/) and the [Fiat-Shamir transform](https://datatracker.ietf.org/doc/draft-irtf-cfrg-fiat-shamir/). To the extent that is possible, ACT should be built on top of them so that there is less for the draft to specify. Note that it may be necessary to add support for $\\vee$-proofs.",
      "createdAt": "2025-08-12T19:34:24Z",
      "updatedAt": "2025-09-08T17:24:41Z",
      "closedAt": null,
      "comments": [
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "Totally agree with this, though I don't have the bandwidth to prioritize this myself at this point. I will happily review text to this end.",
          "createdAt": "2025-08-12T23:47:34Z",
          "updatedAt": "2025-08-12T23:47:34Z"
        }
      ]
    },
    {
      "number": 7,
      "id": "I_kwDOPc24Mc7GlytP",
      "title": "Use case for request context: expiry",
      "url": "https://github.com/SamuelSchlesinger/draft-act/issues/7",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "ACT credentials should expire, for two reasons:\n\n1. Security: The server may want to rate-limit clients over time, say, to $c$ requests/day, where $c$ is the number of credits for each credential issued. Unless credentials expire, issuing one credential/day per client would not be sufficient to enforce the rate limit, since the client could hoard credentials issued over multiple days.\n\n2. Operational: Preventing double spends requires storing all nullifiers accepted for a given server key. This means the cost of the double spending check increases over time as the number of stored nullifiers increases. Once a credential expires, it's no longer necessary to track its nullifiers.\n\nThe draft currently envisions implementing expiry by frequently rotating the server's key. Time would be divided into discrete epochs, say 00:00-23:59 UTC, and each epoch would have its own server key. Clients would need to be configured out-of-band with the corresponding public key for each epoch.\n\nThis imposes an operational burden that may be untenable for some deployments. For example, suppose the clients are operated by company X and credentials are issued by (and presented to) company Y. Suppose further that X requests issuance from Y on behalf of its clients. (This prevents Y from being able to fingerprint clients. It also makes it possible to separate issuance from attestation of who is a \"legitimate\" client, which is helpful in many scenarios. See [RFC 9576](https://datatracker.ietf.org/doc/rfc9576/).)\n\nTo implement this feature, Y would expose an API to X for pulling epoch public keys; X would periodically ping this API and push keys down to its clients. How \"doable\" this is in practice depends on the length of the epoch window. Rotating every day may not be so bad, but rotating every hour would require a lot of coordination.\n\nOne way around this would be to support something like ARC's [request context](https://chris-wood.github.io/draft-arc/draft-yun-cfrg-arc.html#section-4.2.1). Roughly speaking, the request context is some string that the client and server must agree on in order for issuance or presentation to succeed. The context might encode the epoch in which the credential was issued. During presentation, the server would use the _current epoch_ as the request context, thereby rejecting credentials issued too far in the past.\n",
      "createdAt": "2025-08-18T19:09:59Z",
      "updatedAt": "2025-08-25T23:54:51Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "A few thoughts on how we might implement request context.\n\n1. We're already deriving the generators $h_1, h_2, h_3$ (using the notation of the [write up](https://github.com/SamuelSchlesinger/anonymous-credit-tokens/blob/main/docs/design.pdf)) by hashing fixed strings. What about simply incorporating the request context into the hash? \n\n2. The BBS MAC the client gets from the server is over a commitment to a vector that includes the current budget $c$ and the next nullifier $k$. We could either this vector with an additional scalar $w$ that includes the hash of the request context so that the MAC becomes:\n\n    $$A = \\left(g \\cdot h_1^c \\cdot h_2^k \\cdot h_3^w \\cdot  h_4^r \\right)^{1/(x+e)}$$\n\n3. We could tack on a fresh commitment to $w$ to the signed message:\n\n    $$A = \\left(g \\cdot (h_1^c \\cdot h_2^k \\cdot h_3^{r_0}) \\cdot (h_4^w \\cdot h_5^{r_1})\\right)^{1/(x+e)}$$\n\n    where $r_0, r_1$ are random scalars.\n\nThe first one seems like the least invasive, but I'm not sure how it would impact security analysis. In terms of performance, it would be more expensive, since we have to compute the generators at issuance/presentation time rather than at setup time. @armfazh ball parks the cost of each hash to curve to be about 1/4 the cost of scalar multiplication.\n\nThe second one seems pretty natural to me, but I'm not sure how this would impact the ZKPs. Likewise for the third option. Both would cost a bit more in performance.",
          "createdAt": "2025-08-18T19:24:56Z",
          "updatedAt": "2025-08-18T20:15:29Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "I feel like the first is the least invasive, but it isn't great from a deployment perspective: do we have to verify with multiple different keys? I prefer something between the second and third, where we essentially go from MAC-ing `(r, k, c)` to MAC-ing `(r, k, c, epoch)` and using the BBS-show machinery to unveil `epoch` when we present a credential.",
          "createdAt": "2025-08-19T02:03:00Z",
          "updatedAt": "2025-08-19T02:03:00Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> I feel like the first is the least invasive, but it isn't great from a deployment perspective: do we have to verify with multiple different keys?\n\nWhat do you mean by multiple keys? The suggestion is to just change how the generators are derived. You wouldn't need to deploy new keys or anything like that.",
          "createdAt": "2025-08-19T02:12:39Z",
          "updatedAt": "2025-08-19T02:12:39Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "Apologies, I phrased it incorrectly but the point still stands: verifying with different generators.",
          "createdAt": "2025-08-19T14:57:01Z",
          "updatedAt": "2025-08-19T14:57:01Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "Feels nicer to verify once, retrieve the field you were looking for, then note that the epoch is within the tolerable range.",
          "createdAt": "2025-08-19T14:57:35Z",
          "updatedAt": "2025-08-19T14:57:35Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm not sure I'm following. The prover and verifier would generate the same set of points if they have the same request-context string, therefore you would only verify the proof once. If they don't have the same request-context, then verification should fail. This is what we want.",
          "createdAt": "2025-08-19T15:34:53Z",
          "updatedAt": "2025-08-19T15:34:53Z"
        },
        {
          "author": "jkatz2",
          "authorAssociation": "NONE",
          "body": "I agree with @SamuelSchlesinger, conceptually the right thing to do seems to be to simply have the epoch be another attribute field. (I'm not saying other approaches can't work, but any other approaches should be compared to the strawman where we simply add another field.)",
          "createdAt": "2025-08-19T16:53:34Z",
          "updatedAt": "2025-08-19T16:53:34Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "@cjpatton i.e. there is only one acceptable epoch at any given time?",
          "createdAt": "2025-08-20T15:17:28Z",
          "updatedAt": "2025-08-20T15:17:28Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "You could have overlapping epoch windows I suppose. If we keep the attribute generic, I.e., the scalar is the hash of some \"request context\" (using the term from ARC), then it could be left up to he application. I think that's the right thing to do.",
          "createdAt": "2025-08-20T15:21:22Z",
          "updatedAt": "2025-08-20T15:21:22Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "Okay, so it sounds like we are all comfortable with the approach where the expiry is a publicly revealed attribute in the credential, and this is used generically to assist in solving contextual scoping of a token in #8.",
          "createdAt": "2025-08-20T16:55:27Z",
          "updatedAt": "2025-08-20T16:55:27Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "It might be useful to separate \"request context\" and \"presentation context\" into separate attributes, but otherwise that sounds good to me.",
          "createdAt": "2025-08-20T17:32:50Z",
          "updatedAt": "2025-08-20T17:32:50Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "Yes, in particular if we support arbitrary public attributes I think this works.",
          "createdAt": "2025-08-20T21:42:37Z",
          "updatedAt": "2025-08-20T21:42:37Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Consensus from 2025/8/25 call is to solve this by extending ACT to support any number of public attributes (as required by the application).",
          "createdAt": "2025-08-25T23:54:51Z",
          "updatedAt": "2025-08-25T23:54:51Z"
        }
      ]
    },
    {
      "number": 8,
      "id": "I_kwDOPc24Mc7GmHPU",
      "title": "Use case for presentation context: bind presentation to origin",
      "url": "https://github.com/SamuelSchlesinger/draft-act/issues/8",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "cjpatton"
      ],
      "labels": [],
      "body": "ACT could be used to rate limit HTTP requests from clients to an HTTP server. In many such cases, the server will operate multiple \"origins\". For example, the same content delivery network might serve HTTP requests for multiple websites.\n\nIn this deployment scenario, it's useful to be able to enforce the rate limit on a per-origin basis. That is, when the client is issued a token with $c$ credits, it gets to make at most $c$ requests to each origin operated by the server.\n\nI see two ways to do this with ACT as it is, neither of which is ideal:\n\n1. The server could issue $c\\cdot N$ credits, where $N$ is the number of origins. However, the client could just spend all of its token at one origin and thereby bypass the per-origin rate-limit.\n\n2. The server could use separate keys for each origin, but this would require the client to reveal to the issuer which origin it wants to reach.\n\nWhat we really want is something like ARC's [presentation context](https://chris-wood.github.io/draft-arc/draft-yun-cfrg-arc.html#section-4.3-3.1.1) string. For our use case, this string would encode the origin, e.g., $\\mathit{ctx} = \\texttt{example.com}$. It would be great to provide ACT with a similar feature.",
      "createdAt": "2025-08-18T19:39:55Z",
      "updatedAt": "2025-08-26T00:04:52Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "ARC works as follows. For each presentation context $\\mathit{ctx}$, the client initializes a fresh \"presentation\" state. For each presentation, it chooses a random nonce $n$ from $[1..c]$ and computes a tag $t = \\mathsf{PRF}_k(n, \\mathit{ctx})$, where $k$ is a scalar it committed to in its credential. The server tracks these $(n, t)$ pairs on a per-origin basis.\n\nCan we do something similar for ACT? Here's an initial idea that doesn't work: Instead of revealing the nullifier $k$ directly, we might instead reveal $\\mathsf{PRF}_k(\\mathit{ctx})$.\n\n@meyira pointed the following attack: Given credential state $S$ with $c$ spend, a malicious client could present $S$ to  a number of origins, then present each of the re-issued credentials to some target origin. We therefore need some way of binding the re-issued credential to the origin so that it can only be presented there.\n\nAlso, we only know how to instantiate $\\mathsf{PRF}$ with classical assumptions (cf. [2024/1552](https://eprint.iacr.org/2024/1552), Theorem 8.7). We therefore would want to make this feature optional so that not all deployments need to sacrifice PQ privacy.\n",
          "createdAt": "2025-08-18T19:54:24Z",
          "updatedAt": "2025-08-18T19:54:54Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "> The server could use separate keys for each origin, but this would require the client to reveal to the issuer which origin it wants to reach.\n\nCurrently, the vector which we MAC is `(r, k, c)`, but we could instead MAC `(r, k, c, o)` where `o` indicated the origin, and `o` might not be revealed to the issuer upon MAC-ing, i.e. sent as part of the commitment that gets MAC-ed.",
          "createdAt": "2025-08-19T01:56:58Z",
          "updatedAt": "2025-08-19T02:05:00Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "That's a better option from a privacy perspective, but IIRC the client would need to know the issuer it wants during issuance. I think this is too much of a restriction.",
          "createdAt": "2025-08-19T02:14:38Z",
          "updatedAt": "2025-08-19T02:14:38Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "That's fair. I think you could also achieve this via a funny hybrid of ARC and ACT, where you are issued a MAC of `(k, c)` and then you present to origin `o` `Y = PRF_k(origin)`, `c`, along with a proof that there exists a MAC of `(k, c)` such that `Y = PRF_k(origin)`. In response, the issuer would issue you an ACT with `c` tokens in it scoped to origin `o` using the trick I stated above. There is another world where you don't show `c` to the origin but instead sign it under a commitment similar to ACT refunds.",
          "createdAt": "2025-08-19T14:33:43Z",
          "updatedAt": "2025-08-19T14:33:43Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "That's kinda what I was thinking. I'm just not sure how to adjust the ZKPs.",
          "createdAt": "2025-08-19T14:46:43Z",
          "updatedAt": "2025-08-19T14:46:43Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "To me, it almost feels like a separate draft almost? Maybe an extension or another type of document, perhaps, as it is more like a proxied attestation strategy for ACTs rather than a detail of the ACT construction itself.",
          "createdAt": "2025-08-19T14:55:21Z",
          "updatedAt": "2025-08-19T14:55:21Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "Maybe the bit that belongs here is the extra origin field, optionally. It feels that also fits into the same extension that the expiry would use, as well, as they have an identical implementation.",
          "createdAt": "2025-08-19T14:56:12Z",
          "updatedAt": "2025-08-19T14:56:12Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "The feature is pretty incremental ... it seems like it would be too small to have as a standalone doc. In any case, I think the ACT doc would be less useful without this option.",
          "createdAt": "2025-08-19T15:37:46Z",
          "updatedAt": "2025-08-19T15:37:46Z"
        },
        {
          "author": "jkatz2",
          "authorAssociation": "NONE",
          "body": "I'm not sure what all was encompassed by \"this option,\" but I think including support for any number of (public) attributes as part of the ACT makes sense. This would allow for including the origin as one of the attributes. OTOH, extending to a full-fledged combination of ARC and ACT does seem like it would be a separate piece of work.",
          "createdAt": "2025-08-20T14:09:41Z",
          "updatedAt": "2025-08-20T14:09:41Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "I'm definitely interested in this approach, whether or not it is a separate document from the main ACT draft I'm happy to include it in this repository. It seems to allow minimization of a (potential expensive) attestation and it kind of fixes some of the PQ-privacy issues of ARC, where you don't have PQ-privacy for which origins you're interacting with, but you do have PQ-privacy for your interactions on that origin.",
          "createdAt": "2025-08-20T15:21:11Z",
          "updatedAt": "2025-08-20T15:21:11Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "To be clear, I believe we're converging on something like the following:\n\n1. When the credential is issued, it either supports presentation context binding or does not. Support would be indicated by an attribute.\n2. When the credential is presented:\n    - If it supports presentation context, then the client reveals $\\mathsf{PRF}_k(\\mathit{ctx})$, where $\\mathit{ctx}$ is the presentation context. The re-issued credential has an _additional_ attribute, whose value is the hash of $\\mathit{ctx}$.\n    - If it doesn't support presentation context, then the client reveals $k$ as currently specified. The re-issued credential is also as currently specified.\n\nDoes this make sense to folks?",
          "createdAt": "2025-08-20T15:26:44Z",
          "updatedAt": "2025-08-20T15:27:18Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "From my perspective, there are two separate credentials: one is the \"global credential\", which is a MAC of `(k, c)`. Another is the \"origin `o` local credential\" which is a MAC of `(r, k, c, o)`. The client of this protocol would keep the \"global credential\" (we should rename this, just a stand-in) and a map from `o` to \"origin `o` local credential\" similar to how the user keeps a map from `o` to a counter in ARC.",
          "createdAt": "2025-08-20T15:36:51Z",
          "updatedAt": "2025-08-20T15:37:04Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "That's roughly how I think of it as well :)",
          "createdAt": "2025-08-20T16:37:28Z",
          "updatedAt": "2025-08-20T16:37:28Z"
        },
        {
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "body": "Sounds like its time to write it up! There is something really interesting here around public verifiability, it might enable a \"publicly verifiable\" scheme where the global credential is publicly verifiable but rate-limited at each relying party only, so there is no need to share a database, and each ACT is still privately verifiable because it is scoped to the individual relying party, which has become a privately verifying issuer of this ACT. In that case, we actually might not require `o` to be included in the credential, cause we can use a different underlying keypair. Maybe something is wrong with this, I haven't written this down in detail, but wanted to note it here for posterity.",
          "createdAt": "2025-08-20T16:45:30Z",
          "updatedAt": "2025-08-20T16:46:04Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> Sounds like its time to write it up!\n\nMy suggestion would be to handle the more straightforward issues, like #1 and #2, before adding new features. That way we end up with less work in the end.",
          "createdAt": "2025-08-20T16:48:20Z",
          "updatedAt": "2025-08-20T16:48:20Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Conclusion from 2025/8/25: We believe we can implement this feature by composing ARC and ACT. ARC wouldn't need any changes; ACT would need an additional public attribute for binding to the presentation context, but we will get this from https://github.com/SamuelSchlesinger/draft-act/issues/7#issuecomment-3222079464.\n\nWe would use ARC in \"one-show\" mode, where the client gets to show the credential exactly once per-presentation-context. When a client successfully presents ARC in some context, it also gets issued an ACT with $c-1$ credits, where $c$ is bound to the ARC request context.\n\nThis is more or less what's going on in the \"reverse Privacy Pass\" flow (credit @thibmeu for making this observation).\n\nNote that the server can distinguish between a \"first\" showing in a given presentation context and a \"subsequent\" showing: for the latter, there is no ARC presentation; only ACT. Is this a problem for anonymity? If so, we could add ARC presentation as a kind of \"cover\", but this would be expensive (and makes something like ARC + VOPRF more attractive).",
          "createdAt": "2025-08-26T00:04:52Z",
          "updatedAt": "2025-08-26T00:04:52Z"
        }
      ]
    },
    {
      "number": 11,
      "id": "I_kwDOPc24Mc7H1UiO",
      "title": "Choosing an algebraic MAC",
      "url": "https://github.com/SamuelSchlesinger/draft-act/issues/11",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The BBS MAC (currently used by ACT) is\n\n$\\left(A = (x+e)^{-1} \\left(G + \\sum_i m_i \\cdot H_i \\right), e\\right)$\n\nwhere $e$ is a random scalar. The CMZ MAC (as used by ARC) is\n\n$\\left( U, V=({x_0 + \\sum_i x_i \\cdot m_i}) U \\right)$\n\nwhere $U$ is a random element of the group.\n\nHow do we choose between these?\n\n### Security\n\nRelevant papers:\n\n* [2013/516, aka CMZ](https://eprint.iacr.org/2013/516), Theorem 2 claims 128 bits of security (for a 256-bit group) for CMZ, unconditionally, in the generic group model.\n* [2023/275](https://eprint.iacr.org/2023/275), Theorem 2 claims 128 bits of security for BBS in the algebraic group model under the $q$-DL assumption ($q$ is the number of signing queries). Theorem 1 proves security in the standard model under a stronger assumption ($q$-SDH) and with a quadratic loss of concrete security. (Note: On page 17 there's a claim that $q$-SDH and $q$-DL are equivalent in the algebraic group model.) Also, see [this write up](https://github.com/SamuelSchlesinger/authenticated-pseudonyms/blob/dev/design/Private_BBS_Security.pdf) about the BBS MAC in particular.\n* [2024/1552](https://eprint.iacr.org/2024/1552), Theorem 5.1 claims 128 bits of security for a variant of CMZ called \"muCMZ\" in the algebraic group model under the $3$-DL assumption. (This doesn't make sense to me... shouldn't the number of signing queries matter?)\n* [2025/1093](https://eprint.iacr.org/2025/1093) describes an attack on BBS that implies a larger-than-usual curve is required to get 128 bits of security (i.e., Ristretto255 -> Decaf448 or P256 -> P384). The same attack doesn't seem (to me) to be directly applicable to CMZ.\n\n### Statistical anonymity\n\nBBS has statistical anonymity, meaning even a quantum attacker can't link presentations to the client. ARC on the other hand is vulnerable to a quantum attack wherein the server issues a credential under a different secret key without changing the public key.",
      "createdAt": "2025-08-25T17:31:29Z",
      "updatedAt": "2025-09-10T18:13:05Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Here are my thoughts on this so far.\n\nMy main question is whether we need a bigger curve for just BBS or whether we need a bigger curve for (mu)CMZ as well. The current vibe seems to be that we don't, but I'm still not sure what we're basing this conclusion on.\n\nOne way I'm trying to answer this question is to look at how these things are proven secure. If we need to assume $q$-SDH or $q$-DL, where $q$ is the number of chosen message attacks we give the attacker, then [Cheon's attack applies](https://www.iacr.org/archive/eurocrypt2006/40040001/40040001.pdf) and we need a bigger curve.\n\nRight now we're leaning on theorems in different models of computation:\n\n1. BBS has security in the standard model under $q$-SDH and the AGM under $q$-DL\n2. CMZ has unconditional security in the GGM\n3. muCMZ has security in the AGM under $3$-DL\n\nThis is unfortunate because it makes it hard to compare these results to one another. ([GGM and AGM are not as easy to compare as we would like](https://eprint.iacr.org/2022/210).) The best we have is the results for the AGM. But why is that BBS requires $q$-DL but muCMZ only requires $3$-DL?\n\nAfter staring at 2023/275, Theorem 2 for a bit, here's how I currently understand it. In the AGM, an adversary who successfully forges also produces a description of the forgery as a function of its observations over the course of the attack (the parameters sampled by the experiment and requests and responses from signing queries). This functionality is a polynomial, and under certain conditions needed for the reduction, the secret key is a root of the polynomial. The reduction to $q$-DL sets things up so that we can find the roots using $g^x, g^{x^2}, \\ldots, g^{x^q}$ we got as input, where $q$ is the degree of the polynomial.\n\nI've also spent some time on the proof of 2024/1552, Theorem 5.1, but I don't quite have my head around it. Some how need to argue that the degree of the polynomial is constant (i.e., $3$?) rather than dependent on the number of signing queries, but I don't see why this should be the case. To be clear, I have no reason to believe there is a bug in the proof, it's just that it would take me more time than I have right now to understand it well enough to say for sure.\n\nOverall, my impression of the literature is that more is known about the security of BBS than about the security of (mu)CMZ. If this is indeed the case, then all else being equal, I would choose BBS over (mu)CMZ. On the other hand, I don't have enough information to suggest that ARC should replace CMZ with BBS.\n\nJon made another observation that is relevant here: depending on what we want to prove about the algebraic MAC, BBS may be cheaper than (mu)CMZ in terms of the size of the proof. This means that moving to BBS may be worth it even if it requires a larger group (+8 bytes/element with BBS, but CMZ requires more elements). We should consider if this is the case for ARC.",
          "createdAt": "2025-09-10T18:10:38Z",
          "updatedAt": "2025-09-10T18:13:05Z"
        }
      ]
    }
  ],
  "pulls": [
    {
      "number": 6,
      "id": "PR_kwDOPc24Mc6j4QmL",
      "title": "Update references to github repo",
      "url": "https://github.com/SamuelSchlesinger/draft-act/pull/6",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The new name is \"draft-act\".",
      "createdAt": "2025-08-15T18:49:41Z",
      "updatedAt": "2025-08-15T18:58:08Z",
      "baseRepository": "SamuelSchlesinger/draft-act",
      "baseRefName": "main",
      "baseRefOid": "837050a15f183bba998e3a95badf53a101ec6fef",
      "headRepository": "SamuelSchlesinger/draft-act",
      "headRefName": "cjpatton/update-repo-name",
      "headRefOid": "f2458b30f77a253c4203034475360549d6a6791e",
      "closedAt": "2025-08-15T18:58:07Z",
      "mergedAt": "2025-08-15T18:58:07Z",
      "mergedBy": "SamuelSchlesinger",
      "mergeCommit": {
        "oid": "a71be413158b134b432228d028719fd56543663f"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOPc24Mc66QYH0",
          "commit": {
            "abbreviatedOid": "f2458b3"
          },
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-08-15T18:58:03Z",
          "updatedAt": "2025-08-15T18:58:03Z",
          "comments": []
        }
      ]
    },
    {
      "number": 9,
      "id": "PR_kwDOPc24Mc6lPwG4",
      "title": "Replace ERROR/INVALID with specific exceptions",
      "url": "https://github.com/SamuelSchlesinger/draft-act/pull/9",
      "state": "CLOSED",
      "author": "meyira",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The previous implementation returned `INVALID` or`ERROR` to indicate any type of failure. To avoid ambiguity when debugging, this change introduces named raising exceptions (e.g., `InvalidIssuanceVerificationProof`, `DoubleSpendError`) to provide clear, specific details about why an operation failed. This allows calling code to implement a more robust error-handling logic.",
      "createdAt": "2025-08-25T16:23:55Z",
      "updatedAt": "2025-08-25T16:35:28Z",
      "baseRepository": "SamuelSchlesinger/draft-act",
      "baseRefName": "main",
      "baseRefOid": "9bade9f72de7db8a6a68daeba3b5f2fd1a546996",
      "headRepository": "SamuelSchlesinger/draft-act",
      "headRefName": "lena/ACT-add-errors",
      "headRefOid": "bf0024da50f725f84464558645c3da395340801d",
      "closedAt": "2025-08-25T16:35:28Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": []
    },
    {
      "number": 10,
      "id": "PR_kwDOPc24Mc6lP4lK",
      "title": "Replace ERROR/INVALID with specific exceptions",
      "url": "https://github.com/SamuelSchlesinger/draft-act/pull/10",
      "state": "MERGED",
      "author": "meyira",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "meyira"
      ],
      "labels": [],
      "body": "The previous implementation returned `INVALID` or`ERROR` to indicate any type of failure. To avoid ambiguity when debugging, this change introduces named raising exceptions (e.g., `InvalidIssuanceVerificationProof`, `DoubleSpendError`) to provide clear, specific details about why an operation failed. This allows calling code to implement a more robust error-handling logic.",
      "createdAt": "2025-08-25T16:36:38Z",
      "updatedAt": "2025-09-01T10:26:23Z",
      "baseRepository": "SamuelSchlesinger/draft-act",
      "baseRefName": "main",
      "baseRefOid": "9bade9f72de7db8a6a68daeba3b5f2fd1a546996",
      "headRepository": "SamuelSchlesinger/draft-act",
      "headRefName": "lena/ACT-add-errors",
      "headRefOid": "63292d4e3eb9ad08ee69e09b2debd325ebb6eb81",
      "closedAt": "2025-09-01T10:26:23Z",
      "mergedAt": "2025-09-01T10:26:23Z",
      "mergedBy": "meyira",
      "mergeCommit": {
        "oid": "0329f6b6c0ae1bea0e4449dfcaafc2667f9c4111"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOPc24Mc69BQ5R",
          "commit": {
            "abbreviatedOid": "236761a"
          },
          "author": "SamuelSchlesinger",
          "authorAssociation": "OWNER",
          "state": "APPROVED",
          "body": "Approved, only (nonblocking) preference is changing HighBytesSetError to some other option.",
          "createdAt": "2025-08-30T20:45:27Z",
          "updatedAt": "2025-08-30T20:45:27Z",
          "comments": []
        }
      ]
    }
  ]
}